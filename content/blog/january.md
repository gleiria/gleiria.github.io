+++
title = 'Microsimulations - Part 1'
date = 2024-01-31T11:43:42Z
draft = false
+++

The concept of using computers to simulate real-world systems has been around for many decades. However, in recent years, with the democratization and significant cost reductions of computational power, increased data availability, and advancements in artificial inteligence, computational simulations have reached new levels of sophistication and their applications, particularly in the healthcare domain, are expanding very rapidly. This blog post series provides an overview on microsimulations and explores how integrating machine learning and multi-objective optimisation into these systems can effectively tackle a concrete healthcare challenge: optimising type 1 diabetes screening strategies while minimizing costs associated.


Type 1 diabetes (T1D) is an autoimmune condition where our own immune system attacks and destroys insulin-producing beta cells in the pancreas. Children are often diagnosed with T1D too late, and around 1 in 3 end up hospitalised in intensive care with life-threatening diabetic ketoacidosis. Early diagnosis is crucial to avoid this outcome. It was previously thought that screening programmes should target individuals with a family history of the disease. However, 90% of those who develop T1D do not have a family history of the condition, so the best way to identify children early is through general population screening.

A major obstacle to adopting broad population-level screening is identifying strategies that offer the best value for money. Specifically, decision-makers face multiple factors when considering population-level screening. These include, but are not limited to, up-front screening costs, variation in screening method (genetic risk score vs autoantibody alone), optimal age and frequency of screening. Real-world studies in general population screening are of undeniably valuable but face many challenges, including very high costs, logistical complexities, and the time required to yield actionable insights. Additionally, they fail to capture the full spectrum of possible screening strategies and may struggle to adapt to new data in the rapidly evolving healthcare landscape. This is where the potential of microsimulations, machine learning, and optimisation algorithms comes into play. What if we could harness these technologies to find the most effective screening strategies for healthcare systems? By 'most effective,' I mean those strategies that significantly reduce life-threatening diabetic ketoacidosis events (i.e., hospitalisations) at the lowest possible cost.

Microsimulations are individual-based state-transition models that operate at the level of individual entities, such as a person, a cell, or a virus. These models simulate large representative populations of these low-level entities to draw conclusions that apply to higher levels of aggregation such as an entire country or a biological system. They help to address many limitations of deterministic cohort models as they can reflect individual clinical pathways which allows inclusion of stochastic variation in disease progression. Stochastic models are very common in fields like epidemiology, economics, and environmental science, precisely because they can capture the uncertainty and variability inherent in real-world systems. Aditionally, microsimulations do not require the Markov assumption that transition probabilities only depend on the current state so we can introduce â€˜memoryâ€™ into the model's structure. 

In this particular case, the development of the microsimulation system encompasses five main stages: disease modeling, modeling a population of children, computing transition probabilities, multi-objective optimisation, and development of a user interface for the model using Django. Below, we will delve into the first three of these stages. Details on multi-objective optimisation and Django integration will be reserved for later in this series. 

### Disease Modelling

This is where we focus on modelling the biological and clinical progression of the disease. The core of the disease modeling are six distinct health/disease states (figure 1), each encapsulated by its own Python class.
{{< figure src="/images/diagram.png" title="Figure 1: Representation of States in the Microsimulation. Every simulant starts in a healthy state and eventually transitions to various possible intermediate disease states (single auto-antibody(Ab1), multi auto-antibody(mAb1) and dysglycemic) up until the type 1 diabetes state with or without a diabetic ketoacidosis (DKA) event at onset." >}}
The interaction between these classes is crucial for simulating the progression of the disease over time in each individual. Each class has methods that define the rules for transitioning to other states. For example, the "healthy" class has a method that handles the transitions of individuals to either "Autoantibody Positive (Ab1)", Multiple Autoantibodies (mAb1)', or remaining in the 'healthy" state, based on certain criteria or transition probability. In addition to state transitions, these classes also share data with each other and trigger events that influence the overall simulation, such as adjusting individual transition probabalitites or aging simulants at every simulation cycle. 

Also, at this stage of the microsimulation development process there is a significant interaction with clinicians involved in the project. This serves as a preliminary level of model validation, as we utilize their clinical expertise to ensure the model accurately mirrors real-world disease progression. I find these interactions to be of great value as they help to bridge the gap between the computational modeling and practical clinical knowledge. Moreover, it perfectly illustrates the interdisciplinary nature of this type of project which I find extremelly positive.

### Modeling Children

With microsimulations being agend-based simulations, creating and managing a population of simulants (i.e digital children) and their attributes is a critical task. Each digital child have its own individual clinical/demographic/genetic features such as age, genetic risk score, and family history for T1D. Importantly, these attributes are based on real-world data distributions. The idea is that based on individual transition probabilities, we simulate these digital childs through the model one at a time and we keep track of their individual trajectories so that at the end we aggregate results for the entire population. The core representation of simulants and their state information is a simple pandas dataframe. Under this representation rows represent childs while columns correspond to state and/or any other attributes like the ones mentioned above. These columns represent one of several resources that other components can act up on. Each of the actions we need to take regarding the population of simulants corresponds to a manipulation of this pandas dataframe. For example, the addition of new simulants is the creation of new rows, the creation of new state attributes is the creation of columns, and the reading and updating of state attributes is reading and updating the dataframe itself. So now that we modelled the disease as well as a population of children, how do we ensure that individual transition probabilities are reflective of what is observed in the real-world?

### Transition probabilities 
This is where we integrate machine learning into our microsimulation system. The main idea involves fitting survival regression models (LogNormal AFT) to real-world observational data. These are a class of models used in survival analysis, a collection of statistical procedures that deals with the prediction of time until an event of interest take place. These are particularly useful in scenarios where you are not only interested in whether an event will happen, but also in how long it will take for that same event to happen. By fitting a LogNormal AFT model to observational data, we learn the relationship between the patient's features and their likelihood of transitioning from one disease state to another. Once that is done, we integrate these models into our microsimulation system and feed them with the population of digital children, enabling us to compute individual transition probabilities for each child. Practically, we generate a predictive survival function for each individual which provides their probability of 'surviving' (or remaining in the same state) beyond a specified time t. 

With the implementation of disease modeling, the modeling of a population of children, and the computation of individual transition probabilities, we establish what is typically referred to as a baseline simulation. This baseline simulation is used a benchmark against which interventions can be compared and "what if" scenarios tested/implemented. By altering parameters of interest or introducing new variables, the impact of these changes can be evaluated relatively to the baseline. The full implementation of the baseline simulation presents an excellent opportunity to move the system beyond the command line and come up with intuitive methods that help with the storytelling off the all process. The video below presents an animated plot, which visualizes data from our microsimulation over a span of 15 years for 10,000 children. This represents 10% of a simulation that ran for 100,000 individuals. Every dor represents a single child and, as you can see, all children begin their lives in a healthy state, with eventual transitions to other states as the years pass. Importantly, these transitions are computed in real-time and result from the output of the exetrnakl survival regression models integrated into the microsimulation system.

{{< vimeo 907217122 >}}

### Up Next

With a baseline simulation established, we are now well positioned to test multiple "what-if" scenarios very rapidly and in a very cost-effective manner. What would happen if we screened children at different ages? What if every child was screened at the age of three, and only those at high genetic risk at later stages? More importantly, how can we optimise for the most effective screening strategies while incurring the lowest possible costs for health care systems? The search space for potential screening strategies is huge, considering a 15-year timeline simulation where each year could employ 11 different screening strategies, for instance, 0 for screening no one, 1 for screening everyone, and the values from 0.1 to 0.9 representing screening the top 10% to 90%, in increments of 10%, of individuals based on the highest genetic risk scores. This creates a massive search space of possibilities, theoretically expanding to 11^15 possible solutions. In the next post in this series, we will explore how multi-objective optimisation techniques can help us to search for "good enough" solutions at the expense of possibly not finding the absolute best solution. We will delve into a fascinating class of heuristic algorithms inspired by natural evolution and the selection of species, known as genetic algortihms, and explore how these powerful computational methods mimic the process of natural selection to iteratively improve upon solutions to complex problems. Stay tunned! ðŸš€




